{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# TP MNIST PyTorch\n",
    "Dans ce TP, vous allez entraîner un MLP à reconnaître des chiffres manuscrits en utilisant la base de données MNIST et la bibliothèque PyTorch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "### Si vous utilisez un ordinateur de l'Enseirb:\n",
    "#### 1) Lancer une session linux (et non pas windows)\n",
    "#### 2) Aller dans \"Applications\", puis \"Autre\", puis \"conda_pytorch\" (un terminal devrait s'ouvrir)\n",
    "#### 3) Dans ce terminal, taper la commande suivante pour lancer Spyder :  \n",
    "`spyder &`  \n",
    "### Si vous utilisez votre ordinateur personnel, il faudra installer Spyder.  \n",
    "\n",
    "---\n",
    "---\n",
    "## Dans tous les cas, ne pas oublier de configurer Spyder en suivant ces [instructions](https://gbourmaud.github.io/files/configuration_spyder_annotated.pdf).\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I) Préparation de la base de données étiquetées MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base de données de reconnaissance de chiffres manuscrits MNIST est constituée d'environ 70 000 imagettes, chacune de taille 28x28.  \n",
    "  \n",
    "Il s'agit d'une **petite** base de données permettant de faire des apprentissages **en quelques secondes sur CPU**.  \n",
    "  \n",
    "Remarquons qu'il n'y aucun problème pour charger **toute** la base de données en mémoire (70 000 x 28 x 28 valeurs stockées sur 32 bits occupent environ 220 Mo). Il est très rare de se retrouver dans une telle situation, en général la base de données est **trop importante pour être chargée intégralement en mémoire** et il faut être capable de gérer le chargement des données depuis le disque dur **à la demande**.\n",
    "  \n",
    "L'objectif de ce TP étant de maîtriser les principaux outils permettant d'effectuer l'apprentissage d'un réseau de neurones, **nous allons voir comment effectuer ces chargements à la demande**. **Pour se rapprocher le plus possible d'un cas \"classique\" de chargement à la demande**, la base de données MNIST a été réorganisée en créant un fichier `.bmp` par image (donc 70 000 fichiers au total).  \n",
    "  \n",
    "Il va donc falloir prendre quelques précautions, en téléchargeant la base de données, pour que ces 70 000 fichiers soient créés en local sur le disque dur (par exemple en travaillant dans `/tmp`) et non pas à distance sur le serveur de l'Enseirb. **Rappel : votre répertoire \"home\" `~` se situe sur un serveur `/net/...`.** Si vous décompressiez l'archive dans votre \"home\", vous créeriez 70 000 fichiers sur le serveur ! Et chaque accès à un fichier entraînerait un transfert sur le réseau, ce qui serait très inefficace.\n",
    "\n",
    "- Télécharger l'archive de la base de données dans `/tmp` : `wget -P /tmp https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/MNIST/MNIST.tar.gz`\n",
    "- Décompresser l'archive dans `/tmp` : `tar -xzf /tmp/MNIST.tar.gz -C /tmp`\n",
    "- Inspecter les fichiers décompressés. Combien y-a-t-il de données d'entraînement ? de données de test ? Visualiser plusieurs images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II) Chargement des données\n",
    "\n",
    "Rappelons qu'en pratique :\n",
    "* Un apprentissage se fait sur un (ou plusieurs) GPU. Remarque : dans ce TP nous utilisons MNIST qui est une base de données suffisamment petite pour faire des apprentissages sur CPU en quelques secondes. **Mais grâce à PyTorch, le code final pourra également s'exécuter sur GPU de manière transparente, comme nous allons le voir.**\n",
    "* En général un apprentissage est long, donc on veut enchaîner les itérations de descente de gradient stochastique **sans perdre de temps à attendre qu'un minibatch soit chargé en mémoire depuis le disque dur**.\n",
    "  \n",
    "La solution consiste à laisser tourner des processus en tâche de fond **qui préparent des minibatches**. Lorsque la boucle d'apprentissage a fini une itération, elle récupère un minibatch qui est déjà prêt. S'il y a **suffisamment de processus tournant en tâche de fond** alors il y a toujours des minibatches disponibles et ainsi il n'y a pas de temps perdu où la boucle d'apprentissage attend que des données soient chargées depuis le disque dur.  \n",
    "  \n",
    "La bibliothèque PyTorch contient des fonctionnalités permettant d'obtenir un tel résultat, notamment à travers les classes `torch.utils.data.Dataset` et `torch.utils.data.Dataloader`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) La classe `torch.utils.data.Dataset`\n",
    "\n",
    "Dans un premier temps, il faut créer une classe `MNISTDataset` dédiée à la base de données MNIST qui hérite de `torch.utils.data.Dataset`.  La documentation de cette classe est consultable [ici](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html). \n",
    "\n",
    "Cette classe `MNISTDataset` doit contenir au moins : \n",
    "- la méthode `def __init__(self, ...):` qui s'exécute à la création de l'objet. Cette méthode a principalement pour objectif de charger en mémoire la liste des noms des images de la base de données. Attention, il ne faut surtout pas charger toutes les images de la base de données dans cette fonction. Certes cela rentrerait en mémoire pour MNIST car cette base de données est *petite* mais cela ne fonctionnerait pas pour une base de données plus grande. Le chargement d'une image s'effectue dans la méthode `def __getitem__(self, idx):`.\n",
    "- la méthode `def __len__(self):` qui renvoie le nombre de données étiquetées de la base\n",
    "- la méthode `def __getitem__(self, idx):` qui permet de charger et de renvoyer l'image numéro `idx` ainsi que son étiquette et toutes les autres informations jugées nécessaires.\n",
    "\n",
    "Pour gagner du temps, les étapes précédents ont déjà été implémentées : [MNISTDataset.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/MNIST/MNISTDataset.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un nouveau script `main.py`, tester ce `Dataset` en affichant 4 éléments de la base de données MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from MNISTDataset import MNISTDataset\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "path_MNIST_train = '/tmp/MNIST/Training'\n",
    "mean_norm = 0. #0.1306\n",
    "std_norm = 1. #0.3081            \n",
    "training_set = MNISTDataset(path_MNIST_train, mean_norm=mean_norm, std_norm=std_norm)\n",
    "\n",
    "#%% Show 4 pairs of data\n",
    "fig1, axs1 = plt.subplots(ncols=4)\n",
    "\n",
    "offset = 7000\n",
    "for i in range(4):\n",
    "    image, label, _ = training_set[i+offset]\n",
    "    axs1[i].imshow(T.ToPILImage()((image*std_norm)+mean_norm))\n",
    "    axs1[i].set_title('True label {}'.format(label))\n",
    "    \n",
    "plt.pause(1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation des données\n",
    "\n",
    "En pratique, les données doivent être normalisées pour faciliter l'apprentissage. La normalisation s'effectue généralement en calculant la moyenne empirique et l'écart-type empirique de la base de données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "Mean MNIST 0.13059155642986298, Std MNIST 0.30801624059677124\n"
     ]
    }
   ],
   "source": [
    "#%% Compute mean and std\n",
    "mean = 0\n",
    "data_full = []\n",
    "for i in range(len(training_set)):\n",
    "    if(i%10000==0):\n",
    "        print(i)\n",
    "    image, label, _ = training_set[i]\n",
    "    data_full.append(image.ravel().data) #stores all data, only possible because MNIST is small\n",
    "    \n",
    "data_full_concat = torch.cat(data_full)\n",
    "mean = torch.mean(data_full_concat)\n",
    "std = torch.std(data_full_concat)\n",
    "print('Mean MNIST {}, Std MNIST {}'.format(mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez utiliser ces valeurs lorsque vous créez un object MNISTDataset : `training_set = MNISTDataset(path_MNIST_train, mean_norm=0.1306, std_norm=0.3080)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) La classe `torch.utils.data.DataLoader`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que le `Dataset` fonctionne, il suffit de l'utiliser lors de la création d'un `DataLoader` pour que PyTorch se charge de créer des processus qui vont préparer des minibatches en tâche de fond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(dataset = training_set,\n",
    "                                       batch_size=batch_size, #nombre d'éléments d'un minibatch\n",
    "                                       shuffle=True, #mélanger la base de données à la fin de chaque epoch\n",
    "                                       num_workers=2) #nombre de processus dédiées à la préparation des minibatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher les 10 premiers éléments du premier minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, _ = next(iter(train_loader))\n",
    "\n",
    "# Show 10 pairs of data\n",
    "fig2, axs2 = plt.subplots(ncols=10)\n",
    "for i in range(10):\n",
    "    axs2[i].imshow(T.ToPILImage()((images[i,:,:,:]*std_norm)+mean_norm))\n",
    "    axs2[i].set_title('{}'.format(labels[i]))\n",
    "    \n",
    "plt.pause(1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quelle est la taille du tenseur `images` (`images.shape`) ?  En PyTorch, un minibatch d'images est un tenseur 4D : `taille_minibatch x nombre_de_canaux x nombre_de_lignes x nombre_de_colonnes`. \n",
    "- Quelle est la taille du tenseur `labels` ?\n",
    "\n",
    "Afin d'implémenter un entraînement avec arrêt prématuré, il nous faut également un dataloader de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_MNIST_valid = '/tmp/MNIST/Validation'                \n",
    "valid_set = MNISTDataset(path_MNIST_valid)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset = valid_set,\n",
    "                                       batch_size=batch_size,\n",
    "                                       shuffle=False,#inutile de mélanger pour la validation\n",
    "                                       num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV) MLP sur MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que le `DataLoader` de MNIST est prêt, vous pouvez reprendre et adapter le code du MLP obtenu à la fin du `TP MLP PyTorch jouet` [main_MLP_two_layers_pytorch_with_optim.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/misc/main_MLP_two_layers_pytorch_with_optim.py) (avec le fichier [utils.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/misc/utils.py)) afin de lancer un apprentissage sur la base de données MNIST.\n",
    "\n",
    "#### 0) Attention, le dataloader ressort des tenseurs de taille `taille_minibatch x nombre_de_canaux x nombre_de_lignes x nombre_de_colonnes` alors qu'un MLP fonctionne sur un minibatch de vecteurs : `taille_minibatch x taille_vecteur`. Vous pouvez vectoriser les 3 dernières dimensions d'un tenseur de taille `Mx1x28x28` (dans le but d'obtenir un tenseur de taille `Mx784`) en utilisant la méthode `.view(-1, 784)`.\n",
    "#### 1) Séparer l'architecture du code d'entraînement en mettant la définition de la classe `MLP` dans un fichier `MLP.py`.\n",
    "#### 2) Lancer un apprentissage sur un seul minibatch pour vous assurer que le coût atteint rapidement (presque) zéro, ce qui permet d'évacuer beaucoup de bugs présents dans votre code.\n",
    "#### 3) Implémenter un arrêt prématuré en codant une fonction de validation permettant d'évaluer les performances du réseau à la fin de chaque epoch (utiliser `with torch.no_grad():` car nous n'avons pas besoin de calculer de gradient pendant la validation). Il faudra stocker les paramètres du réseau si les performances sont les meilleurs obtenues jusqu'à présent : `torch.save(model.state_dict(), './model.pt')`. Ajouter la courbe de validation aux affichages.\n",
    "#### 4) Vous pouvez stopper l'apprentissage manuellement lorsque vous constatez qu'il n'y a plus d'amélioration des performances.\n",
    "---\n",
    "\n",
    "Si vous êtes bloqués, voici un exemple de correction : [main_MLP_MNIST_wo_tensorboard.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/MNIST/main_MLP_MNIST_wo_tensorboard.py) avec le fichier [MLP.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/MNIST/MLP.py)  \n",
    "\n",
    "Après avoir effectué un apprentissage, vous pouvez tester votre modèle avec le code suivant : [main_test_model.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/MNIST/main_test_model.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code de correction atteint rapidement un taux de bonne classification de 95%. Il est possible de gagner encore quelques points en rajoutant des couches (actuellement le MLP n'a qu'une couche cachée), où encore en rajoutant une évolution du pas d'apprentissage comme [une réduction sur plateau](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html).\n",
    "\n",
    "**Affichages**  \n",
    "Le code de correction utilise Matplotlib pour réaliser les affichages. Nous allons désormais utiliser un outil dédié : **TensorBoard**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V) TensorBoard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard est un outil de visualisation dédié aux expériences d'appentissage automatique. Il permet notamment de tracer des courbes au cours de l'entraînement ou encore de superposer des courbes issues de différents entraînement.\n",
    "Un exemple d'utilisation est présenté ici : https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html\n",
    "\n",
    "L'objectif de cette partie est d'utiliser cet outil, en rajoutant quelques lignes de code à votre code d'entraînement du MLP sur MNIST (essentiellement `from torch.utils.tensorboard import SummaryWriter\n",
    "`, `writer = SummaryWriter()`, `writer.add_scalar(...)`)\n",
    " , pour afficher des informations relatives à l'entraînement en cours (courbe du coût d'apprentissage, courbe du coût de validation, courbe de la précision de validation, valeur du pas d'apprentissage au cours du temps, valeurs de certains gradients, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI) MNIST décentré\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les images de la base de données MNIST sont de taille 28x28. Dans chaque image, le chiffre se situe au centre de l'image. \n",
    "\n",
    "L'objectif de cette partie est de modifier le `Dataset` pour obtenir des images de taille 56x56 où le chiffre n'est plus centré. Ceci peut par exemple être implémenté dans la méthode `__get_item__` en générant une translation aléatoire (en x et en y) et en l'appliquant à l'image chargée.\n",
    "\n",
    "Cette nouvelle base de donnée, qu'on appellera *MNISTTranslation*, correspond à un problème d'apprentissage supervisé plus difficile que le problème initial. Pourquoi ? \n",
    "\n",
    "Lancer un entraînement avec le MLP précédemment implémenté. Que constatez-vous ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
