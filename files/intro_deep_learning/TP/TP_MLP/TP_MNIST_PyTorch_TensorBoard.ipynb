{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# TP MNIST\n",
    "Dans ce TP, vous allez utiliser la base de données de reconnaissance de chiffres manuscrits MNIST pour entraîner un réseau de neurones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "### Si vous utilisez un ordinateur de l'Enseirb:\n",
    "#### 1) Lancer une session linux (et non pas windows)\n",
    "#### 2) Ouvrir un terminal et taper les commandes suivantes :  \n",
    "`source /usr/local/bin/launcher/conda_pytorch`  \n",
    "\n",
    "\n",
    "`spyder &`  \n",
    "#### 3) Configurer Spyder en suivant ces instructions [Lien configuration Spyder](https://mycore.cnrs.fr/index.php/s/1aoDZJs9SYnlR8h).\n",
    "### Si vous utilisez votre ordinateur personnel, il faudra installer la bibliothèque PyTorch ainsi que le paquet Tensorboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I) Préparation de la base de données étiquetées MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base de données de reconnaissance de chiffres manuscrits MNIST est disponible [ici](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/MNIST.tar.gz).\n",
    "\n",
    "- Décompresser l'archive, par exemple dans `/tmp`.\n",
    "- Inspecter les fichiers décompressés. Combien y-a-t-il de données d'entraînement ? de données de test ? Visualiser plusieurs images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II) La classe `torch.utils.data.Dataset`\n",
    "\n",
    "La bibliothèque PyTorch contient des fonctionnalités permettant de générer automatiquement et efficacement (en utilisant plusieurs processus) des minibatchs sur CPU, notamment à travers les classes `torch.utils.data.Dataset` et `torch.utils.data.Dataloader`. \n",
    "\n",
    "Un `DataLoader` prend en entrée un `Dataset`. Ainsi il va falloir créer une classe `MNISTDataset` dédiée à la base de données MNIST qui héritera de `torch.utils.data.Dataset`.  La documentation de cette classe est consultable dans le terminal Spyder : `help(torch.utils.data.Dataset)` ou ici : https://pytorch.org/tutorials/beginner/basics/data_tutorial.html. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Créer un fichier `MNISTDataset.py`\n",
    "- Créer une classe `MNISTDataset` qui hérite de `torch.utils.data.Dataset` (`class MNISTDataset(t.utils.data.Dataset):`)\n",
    "\n",
    "Cette classe `MNISTDataset` doit contenir au moins : \n",
    "- la méthode `def __init__(self, ...):` qui s'exécute à la création de l'objet. Cette méthode a principalement pour objectif de charger en mémoire la liste des noms des images de la base de données. Attention, il ne faut surtout pas charger toutes les images de la base de données dans cette fonction. Certes cela rentrerait en mémoire pour MNIST car cette base de données est *petite* mais cela ne fonctionnerait pas pour une base de données plus grande. Le chargement d'une image s'effectue dans la méthode `def __getitem__(self, idx):`.\n",
    "- la méthode `def __len__(self):` qui renvoie le nombre de données étiquetées de la base\n",
    "- la méthode `def __getitem__(self, idx):` qui permet de charger et de renvoyer l'image numéro `idx` ainsi que son étiquette et toutes les autres informations jugées nécessaires.\n",
    "\n",
    "Si vous rencontrez des difficultés pour implémenter ce `Dataset`, vous trouverez ci-après une version fonctionnelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import PIL.Image as Image\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "\n",
    "\n",
    "class MNISTDataset(t.utils.data.Dataset):\n",
    "    def __init__(self, MNIST_dir):\n",
    "        \n",
    "        self.MNIST_dir = MNIST_dir\n",
    "        self.num_classes = 10\n",
    "        \n",
    "        self.img_list = []\n",
    "        self.label_list = []\n",
    "        for i in range(self.num_classes):\n",
    "            path_cur = os.path.join(self.MNIST_dir,'{}'.format(i))\n",
    "            img_list_cur = os.listdir(path_cur)\n",
    "            \n",
    "            img_list_cur = [os.path.join('{}'.format(i), file) for file in img_list_cur]\n",
    "\n",
    "            self.img_list += img_list_cur\n",
    "            \n",
    "            label_list_cur = [i] * len(img_list_cur)\n",
    "            self.label_list += label_list_cur\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.label_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_path = os.path.join(self.MNIST_dir, self.img_list[idx])\n",
    "        \n",
    "        I_PIL = Image.open(img_path)\n",
    "        \n",
    "        I = T.ToTensor()(I_PIL)\n",
    "\n",
    "        return I, t.tensor(self.label_list[idx]), img_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un nouveau script `main.py`, tester ce `Dataset` en affichant 4 éléments de la base de données MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from MNISTDataset import MNISTDataset\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path_MNIST_train = '/tmp/MNIST/Training'                \n",
    "training_set = MNISTDataset(path_MNIST_train)\n",
    "\n",
    "plt.figure(1)\n",
    "for i in range(4):\n",
    "    image, label, _ = training_set[i]\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.imshow(T.ToPILImage()(image))\n",
    "    plt.title('True label {}'.format(label))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III) La classe `torch.utils.data.DataLoader`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que le `Dataset` fonctionne, il suffit de l'utiliser lors de la création d'un `DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = t.utils.data.DataLoader(dataset = training_set,\n",
    "                                       batch_size=batch_size,\n",
    "                                       shuffle=True,\n",
    "                                       num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher les 4 premiers éléments du premier minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, _ = next(iter(train_loader))\n",
    "\n",
    "plt.figure(2)\n",
    "for i in range(4):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.imshow(T.ToPILImage()(images[i,:,:,:]))\n",
    "    plt.title('True label {}'.format(labels[i]))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quelle est la taille du tenseur `images` ? En PyTorch, un minibatch d'images est un tenseur 4D : `taille_minibatch x nombre_de_canaux x nombre_de_lignes x nombre_de_colonnes`. \n",
    "- Quelle est la taille du tenseur `labels` ?\n",
    "\n",
    "Lors d'un entraînement avec arrêt prématuré, nous utiliserons la base de données de *testing* comme base de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_MNIST_valid = '/tmp/MNIST/Testing'                \n",
    "valid_set = MNISTDataset(path_MNIST_valid)\n",
    "valid_loader = t.utils.data.DataLoader(dataset = valid_set,\n",
    "                                       batch_size=batch_size,\n",
    "                                       shuffle=False,\n",
    "                                       num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV) MLP sur MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que le `DataLoader` de MNIST est prêt, vous pouvez reprendre et adapter le code du MLP obtenu à la fin du TP précédent (`TP MLP PyTorch jouet`) afin de lancer un apprentissage des paramètres du MLP sur la base de données MNIST.\n",
    "\n",
    "---\n",
    "**COMMENCER PAR LANCER UN APPRENTISSAGE SUR UN SEUL MINIBATCH POUR EVACUER RAPIDEMENT LA PLUPART DES BUGS PRESENTS DANS VOTRE CODE**\n",
    "\n",
    "---\n",
    "\n",
    "Vous trouverez ci-après un exemple de code fonctionnel permettant de réaliser un apprentissage d'un MLP sur MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from MNISTDataset import MNISTDataset\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "path_MNIST_train = '/tmp/MNIST/Training'                \n",
    "training_set = MNISTDataset(path_MNIST_train)\n",
    "\n",
    "plt.figure(1)\n",
    "for i in range(4):\n",
    "    image, label, _ = training_set[i]\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.imshow(T.ToPILImage()(image))\n",
    "    plt.title('True label {}'.format(label))\n",
    "    \n",
    "plt.pause(1.)\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(dataset = training_set,\n",
    "                                       batch_size=batch_size,\n",
    "                                       shuffle=True,\n",
    "                                       num_workers=2)\n",
    "images, labels, _ = next(iter(train_loader))\n",
    "\n",
    "plt.figure(2)\n",
    "for i in range(4):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.imshow(T.ToPILImage()(images[i,:,:,:]))\n",
    "    plt.title('True label {}'.format(labels[i]))\n",
    "    \n",
    "plt.pause(1.)\n",
    "\n",
    "path_MNIST_valid = '/tmp/MNIST/Testing'                \n",
    "valid_set = MNISTDataset(path_MNIST_valid)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset = valid_set,\n",
    "                                       batch_size=batch_size,\n",
    "                                       shuffle=False,\n",
    "                                       num_workers=2)\n",
    "\n",
    "   \n",
    "        \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, H, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.C = 10\n",
    "        self.D = input_size\n",
    "        self.H = H\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(self.D, self.H) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(self.H, self.C)  \n",
    "        \n",
    "        \n",
    "    def forward(self,X):\n",
    "    \n",
    "        X1 = self.fc1(X) #NxH\n",
    "        X2 = self.relu(X1) #NxH\n",
    "        O = self.fc2(X2) #NxC\n",
    "    \n",
    "        return O\n",
    "    \n",
    "\n",
    "def validation(valid_loader, model):\n",
    "    # Test the model\n",
    "    # In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels, _ in valid_loader:\n",
    "            images_vec = images.view(-1, 28*28)\n",
    "            \n",
    "            outputs = model(images_vec)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return (correct, total)\n",
    "\n",
    "#%% HYPERPARAMETERS\n",
    "H = 30\n",
    "lr = 1e-2 #learning rate\n",
    "beta = 0.9 #momentum parameter\n",
    "n_epoch = 100 #number of iterations\n",
    "input_size = 784\n",
    "\n",
    "model = MLP(H,input_size)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=beta)  \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_batch = len(train_loader) #600 batches each containing 100 images = 60000 images\n",
    "\n",
    "training_loss_v = []\n",
    "valid_acc_v = []\n",
    "\n",
    "(correct, total) = validation(valid_loader, model)\n",
    "print ('Epoch [{}/{}], Valid Acc: {} %'\n",
    "           .format(0, n_epoch, 100 * correct / total))\n",
    "valid_acc_v.append(correct / total)\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    \n",
    "    loss_tot = 0\n",
    "\n",
    "    for i, (images, labels,_) in enumerate(train_loader):\n",
    "\n",
    "        # Reshape images to (batch_size, input_size), actual shape is (batch_size, 1, 28, 28)\n",
    "        images_vec = images.view(-1, input_size)\n",
    "            \n",
    "        #Forward Pass\n",
    "        O = model.forward(images_vec)\n",
    "        \n",
    "        #Compute Loss\n",
    "        l = criterion(O, labels)\n",
    "        \n",
    "        #Print Loss\n",
    "        loss_tot += l.item()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Batch Loss: {:.4f}' \n",
    "                   .format(epoch+1, n_epoch, i+1, num_batch, l.item()/len(labels)))\n",
    "    \n",
    "        #Backward Pass (Compute Gradient)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        \n",
    "        #Update Parameters\n",
    "        optimizer.step()    \n",
    "        \n",
    "    \n",
    "    (correct, total) = validation(valid_loader, model)\n",
    "    print ('Epoch [{}/{}], Training Loss: {:.4f}, Valid Acc: {} %'\n",
    "           .format(epoch+1, n_epoch, loss_tot/len(training_set), 100 * correct / total))\n",
    "    training_loss_v.append(loss_tot/len(training_set))\n",
    "    valid_acc_v.append(correct / total)\n",
    "    \n",
    "    \n",
    "#%% plot results\n",
    "plt.figure(2)\n",
    "plt.clf()\n",
    "plt.plot(training_loss_v,'r',label='Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(3)\n",
    "plt.clf()\n",
    "plt.plot(valid_acc_v,'g',label='Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "(images, labels,_) = iter(valid_loader).next()\n",
    "images_vec = images.reshape(-1, 28*28)\n",
    "outputs = model(images_vec)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "plt.figure(4)\n",
    "plt.clf()\n",
    "for i in range(7):\n",
    "    for j in range(3):\n",
    "        image = images[i+(7*j),:]\n",
    "        plt.subplot(3,7,1+i+(7*j))\n",
    "        plt.imshow(T.ToPILImage()(image))\n",
    "        plt.title('True {} / Pred {}'.format(labels[i+(7*j)], predicted[i+(7*j)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Influence de la plage des valeurs des données en entrée du réseau**\n",
    "\n",
    "La fonction `ToTensor` utilisée dans le `Dataset` a automatiquement normalisé le tenseur avec des valeurs dans $[0, 1]$ alors que l'image initiale avait des valeurs dans l'intervalle $[0, 255]$. \n",
    "\n",
    "Lancer un entraînement en multipliant le tenseur en entrée du réseau par 255 (afin que ses valeurs soient dans l'intervalle $[0, 255]$). Vous devriez constater que l'entraînement est beaucoup plus long, ou bien qu'il n'y a carrément pas de convergence. \n",
    "\n",
    "**Affichages**\n",
    "\n",
    "Le code ci-dessus réalise peu d'affichages permettant de contrôler le bon déroulement de l'apprentissage. Pour ce faire, nous allons utiliser un outil supplémentaire : **TensorBoard**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V) TensorBoard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard est un outil de visualisation dédié aux expériences d'appentissage automatique. Il permet notamment de tracer des courbes au cours de l'entraînement ou encore de superposer des courbes issues de différents entraînement.\n",
    "Un exemple d'utilisation est présenté ici : https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html\n",
    "\n",
    "L'objectif de cette partie est d'utiliser cet outil, en rajoutant quelques lignes de code à votre code d'entraînement du MLP sur MNIST (essentiellement `from torch.utils.tensorboard import SummaryWriter\n",
    "`, `writer = SummaryWriter()`, `writer.add_scalar(...)`)\n",
    " , pour afficher des informations relatives à l'entraînement en cours (courbe du coût d'apprentissage, courbe du coût de validation, courbe de la précision de validation, valeur du pas d'apprentissage au cours du temps, valeurs de certains gradients, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI) MNIST décentré\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les images de la base de données MNIST sont de taille 28x28. Dans chaque image, le chiffre se situe au centre de l'image. \n",
    "\n",
    "L'objectif de cette partie est de modifier le `Dataset` pour obtenir des images de taille 56x56 où le chiffre n'est plus centré. Ceci peut par exemple être implémenté dans la méthode `__get_item__` en générant une translation aléatoire (en x et en y) et en l'appliquant à l'image chargée.\n",
    "\n",
    "Cette nouvelle base de donnée, qu'on appellera *MNISTTranslation*, correspond-elle à un problème d'apprentissage supervisé plus difficile que le problème initial ? Pourquoi ? \n",
    "\n",
    "Lancer un entraînement avec le MLP précédemment implémenté. Que constatez-vous ? Pourquoi ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
