{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# TP MNIST PyTorch\n",
    "Dans ce TP, vous allez entraîner un MLP à reconnaître des chiffres manuscrits en utilisant la base de données MNIST et la bibliothèque PyTorch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "### Si vous utilisez un ordinateur de l'Enseirb:\n",
    "#### 1) Lancer une session linux (et non pas windows)\n",
    "#### 2) Aller dans \"Applications\", puis \"Autre\", puis \"conda_pytorch\" (un terminal devrait s'ouvrir)\n",
    "#### 3) Dans ce terminal, taper la commande suivante pour lancer Spyder :  \n",
    "`spyder &`  \n",
    "### Si vous utilisez votre ordinateur personnel, il faudra installer Spyder.  \n",
    "\n",
    "---\n",
    "---\n",
    "## Dans tous les cas, ne pas oublier de configurer Spyder en suivant ces [instructions](https://gbourmaud.github.io/files/configuration_spyder_annotated.pdf).\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I) Introduction à PyTorch et à l'Autograd\n",
    "\n",
    "[Notebook Introduction à PyTorch et à l'Autograd](https://github.com/gbourmaud/gbourmaud.github.io/blob/master/files/intro_deep_learning/TP/TP_MLP/IA201/intro_autograd.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II) Préparation de la base de données étiquetées MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base de données de reconnaissance de chiffres manuscrits MNIST est constituée d'environ 70 000 imagettes, chacune de taille 28x28.  \n",
    "  \n",
    "Il s'agit d'une **petite** base de données permettant de faire des apprentissages **en quelques secondes sur CPU**.  \n",
    "  \n",
    "Remarquons qu'il n'y aucun problème pour charger **toute** la base de données en mémoire (70 000 x 28 x 28 valeurs stockées sur 32 bits occupent environ 220 Mo). Il est très rare de se retrouver dans une telle situation, en général la base de données est **trop importante pour être chargée intégralement en mémoire** et il faut être capable de gérer le chargement des données depuis le disque dur **à la demande**.\n",
    "  \n",
    "L'objectif de ce TP étant de maîtriser les principaux outils permettant d'effectuer l'apprentissage d'un réseau de neurones, **nous allons voir comment effectuer ces chargements à la demande**. **Pour se rapprocher le plus possible d'un cas \"classique\" de chargement à la demande**, la base de données MNIST a été réorganisée en créant un fichier `.bmp` par image (donc 70 000 fichiers au total).  \n",
    "  \n",
    "Il va donc falloir prendre quelques précautions, en téléchargeant la base de données, pour que ces 70 000 fichiers soient créés en local sur le disque dur (par exemple en travaillant dans `/tmp`) et non pas à distance sur le serveur de l'Enseirb. **Rappel : votre répertoire \"home\" `~` se situe sur un serveur `/net/...`.** Si vous décompressiez l'archive dans votre \"home\", vous créeriez 70 000 fichiers sur le serveur ! Et chaque accès à un fichier entraînerait un transfert sur le réseau, ce qui serait très inefficace.\n",
    "\n",
    "- Télécharger l'archive de la base de données dans `/tmp` : `wget -P /tmp https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/MNIST/MNIST.tar.gz`\n",
    "- Décompresser l'archive dans `/tmp` : `tar -xzf /tmp/MNIST.tar.gz -C /tmp`\n",
    "- Inspecter les fichiers décompressés. Combien y-a-t-il de données d'entraînement ? de données de test ? Visualiser plusieurs images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III) Chargement des données\n",
    "\n",
    "Rappelons qu'en pratique :\n",
    "* Un apprentissage se fait sur un (ou plusieurs) GPU. Remarque : dans ce TP nous utilisons MNIST qui est une base de données suffisamment petite pour faire des apprentissages sur CPU en quelques secondes. **Mais grâce à PyTorch, le code final pourra également s'exécuter sur GPU de manière transparente, comme nous allons le voir.**\n",
    "* En général un apprentissage est long, donc on veut enchaîner les itérations de descente de gradient stochastique **sans perdre de temps à attendre qu'un minibatch soit chargé en mémoire depuis le disque dur**.\n",
    "  \n",
    "La solution consiste à laisser tourner des processus en tâche de fond **qui préparent des minibatches**. Lorsque la boucle d'apprentissage a fini une itération, elle récupère un minibatch qui est déjà prêt. S'il y a **suffisamment de processus tournant en tâche de fond** alors il y a toujours des minibatches disponibles et ainsi il n'y a pas de temps perdu où la boucle d'apprentissage attend que des données soient chargées depuis le disque dur.  \n",
    "  \n",
    "La bibliothèque PyTorch contient des fonctionnalités permettant d'obtenir un tel résultat, notamment à travers les classes `torch.utils.data.Dataset` et `torch.utils.data.Dataloader`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) La classe `torch.utils.data.Dataset`\n",
    "\n",
    "Dans un premier temps, il faut créer une classe `MNISTDataset` dédiée à la base de données MNIST qui hérite de `torch.utils.data.Dataset`.  La documentation de cette classe est consultable [ici](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html). \n",
    "\n",
    "Cette classe `MNISTDataset` doit contenir au moins : \n",
    "- la méthode `def __init__(self, ...):` qui s'exécute à la création de l'objet. Cette méthode a principalement pour objectif de charger en mémoire la liste des noms des images de la base de données. Attention, il ne faut surtout pas charger toutes les images de la base de données dans cette fonction. Certes cela rentrerait en mémoire pour MNIST car cette base de données est *petite* mais cela ne fonctionnerait pas pour une base de données plus grande. Le chargement d'une image s'effectue dans la méthode `def __getitem__(self, idx):`.\n",
    "- la méthode `def __len__(self):` qui renvoie le nombre de données étiquetées de la base\n",
    "- la méthode `def __getitem__(self, idx):` qui permet de charger et de renvoyer l'image numéro `idx` ainsi que son étiquette et toutes les autres informations jugées nécessaires.\n",
    "\n",
    "Pour gagner du temps, les étapes précédents ont déjà été implémentées : [MNISTDataset.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/MNIST/MNISTDataset.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un nouveau script `main.py`, tester ce `Dataset` en affichant 4 éléments de la base de données MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from MNISTDataset import MNISTDataset\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "path_MNIST_train = '/tmp/MNIST/Training'\n",
    "mean_norm = 0. #0.1306\n",
    "std_norm = 1. #0.3081            \n",
    "training_set = MNISTDataset(path_MNIST_train, mean_norm=mean_norm, std_norm=std_norm)\n",
    "\n",
    "#%% Show 4 pairs of data\n",
    "fig1, axs1 = plt.subplots(ncols=4)\n",
    "\n",
    "offset = 7000\n",
    "for i in range(4):\n",
    "    image, label, _ = training_set[i+offset]\n",
    "    axs1[i].imshow(T.ToPILImage()((image*std_norm)+mean_norm))\n",
    "    axs1[i].set_title('True label {}'.format(label))\n",
    "    \n",
    "plt.pause(1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation des données\n",
    "\n",
    "En pratique, les données doivent être normalisées pour faciliter l'apprentissage. La normalisation s'effectue généralement en calculant la moyenne empirique et l'écart-type empirique de la base de données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "Mean MNIST 0.13059155642986298, Std MNIST 0.30801624059677124\n"
     ]
    }
   ],
   "source": [
    "#%% Compute mean and std\n",
    "mean = 0\n",
    "data_full = []\n",
    "for i in range(len(training_set)):\n",
    "    if(i%10000==0):\n",
    "        print(i)\n",
    "    image, label, _ = training_set[i]\n",
    "    data_full.append(image.ravel().data) #stores all data, only possible because MNIST is small\n",
    "    \n",
    "data_full_concat = torch.cat(data_full)\n",
    "mean = torch.mean(data_full_concat)\n",
    "std = torch.std(data_full_concat)\n",
    "print('Mean MNIST {}, Std MNIST {}'.format(mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez utiliser ces valeurs lorsque vous créez un object MNISTDataset : `training_set = MNISTDataset(path_MNIST_train, mean_norm=0.1306, std_norm=0.3080)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) La classe `torch.utils.data.DataLoader`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que le `Dataset` fonctionne, il suffit de l'utiliser lors de la création d'un `DataLoader` pour que PyTorch se charge de créer des processus qui vont préparer des minibatches en tâche de fond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(dataset = training_set,\n",
    "                                       batch_size=batch_size, #nombre d'éléments d'un minibatch\n",
    "                                       shuffle=True, #mélanger la base de données à la fin de chaque epoch\n",
    "                                       num_workers=2) #nombre de processus dédiées à la préparation des minibatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher les 10 premiers éléments du premier minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, _ = next(iter(train_loader))\n",
    "\n",
    "# Show 10 pairs of data\n",
    "fig2, axs2 = plt.subplots(ncols=10)\n",
    "for i in range(10):\n",
    "    axs2[i].imshow(T.ToPILImage()((images[i,:,:,:]*std_norm)+mean_norm))\n",
    "    axs2[i].set_title('{}'.format(labels[i]))\n",
    "    \n",
    "plt.pause(1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quelle est la taille du tenseur `images` (`images.shape`) ?  En PyTorch, un minibatch d'images est un tenseur 4D : `taille_minibatch x nombre_de_canaux x nombre_de_lignes x nombre_de_colonnes`. \n",
    "- Quelle est la taille du tenseur `labels` ?\n",
    "\n",
    "Afin d'implémenter un entraînement avec arrêt prématuré, il nous faut également un dataloader de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_MNIST_valid = '/tmp/MNIST/Validation'                \n",
    "valid_set = MNISTDataset(path_MNIST_valid)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset = valid_set,\n",
    "                                       batch_size=batch_size,\n",
    "                                       shuffle=False,#inutile de mélanger pour la validation\n",
    "                                       num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV) MLP sur MNIST en PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le [TP précédent](https://github.com/gbourmaud/gbourmaud.github.io/blob/master/files/intro_deep_learning/TP/TP_MLP/IA200/TP_MLP_numpy_jouet_et_MNIST.ipynb) vous aviez implémenté un MLP en Numpy sur MNIST. L'objectif de cette partie est d'obtenir le même résultat en utilisant les fonctionnalités de PyTorch. Pour cela, vous pouvez soit repartir de votre code, soit de la correction fournie lors du TP précédent : [main_MLP_two_layers_MNIST.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/IA200/main_MLP_two_layers_MNIST.py) et [utils.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/IA200/utils.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Utilisation du DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors du TP précédent, MNIST avait été chargé entièrement en mémoire (ce qui est uniquement possible car MNIST est une petite base de données), et la génération de minibatches se faisait \"à la main\" dans le processus principal. Maintenant que le `DataLoader` de MNIST est prêt, vous pouvez reprendre et adapter le code du TP précédent afin de lancer un apprentissage sur la base de données MNIST **en utilisant ce `DataLoader`**.\n",
    "\n",
    "#### Attention, le dataloader ressort des tenseurs de taille `taille_minibatch x nombre_de_canaux x nombre_de_lignes x nombre_de_colonnes` alors qu'un MLP fonctionne sur un minibatch de vecteurs : `taille_minibatch x taille_vecteur`. Vous pouvez vectoriser les 3 dernières dimensions d'un tenseur de taille `Mx1x28x28` (dans le but d'obtenir un tenseur de taille `Mx784`) en utilisant la méthode `.view(-1, 784)`.\n",
    "\n",
    "Si vous êtes bloqués, vous pouvez vous référer à cette correction : [main_MLP_two_layers_MNIST_dataloader.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/IA201/correction/main_MLP_two_layers_MNIST_dataloader.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Utilisation de la fonctionnalité *autograd*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de pouvoir utiliser la fonctionnalité *autograd*, il faut modifier le code pour travailler avec des `torch.tensor` et non pas des `np.array`. Cette modification étant fastidieuse, voici le résultat : [main_MLP_two_layers_MNIST_dataloader_pytorch.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/IA201/correction/main_MLP_two_layers_MNIST_dataloader_pytorch.py) et [utils_pytorch.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/IA201/correction/utils_pytorch.py)\n",
    "\n",
    "L'objectif de cette partie consiste à remplacer, dans le code de la partie précédente, l'implémentation manuelle de la rétropropagation par la fonctionnalité *autograd*. Ainsi :\n",
    "* la méthode `def backward(self,dc_dS, S, X2, X1, X0)` de la classe `class MLP` doit être supprimée, et l'appel à cette méthode remplacé par l'appel à la méthode `.backward()` de l'autograd comme vu précédemment (`S.backward(dc_dS)`),\n",
    "* il faut activer le calcul des gradients des paramètres `W1`, `b1`, etc. (méthode `.requires_grad_()`), supprimer les variables gradients `dc_dW1`, `dc_db1`, etc.  \n",
    "* il faut modifier `GradientDescentWithMomentum` pour qu'il utilise les champs `.grad` des paramètres (car les variables gradients `dc_dW1`, `dc_db1`, etc. n'existent plus), et mettre au début de la méthode `def step(self):` `with t.no_grad():` pour que les opérations qui suivent ne soient pas mises dans le graphe de calcul.\n",
    "\n",
    "\n",
    "Le code obtenu devrait fonctionner exactement comme précédemment.  \n",
    "Si vous êtes bloqués, vous pouvez vous référer à cette correction : [main_MLP_two_layers_MNIST_autograd_pytorch.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/IA201/correction/main_MLP_two_layers_MNIST_autograd_pytorch.py) et [utils_autograd.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/IA201/correction/utils_autograd.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Utilisation du paquet `torch.nn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En plus de la fonctionnalité autograd, la bibliothèque PyTorch contient de nombreuses implémentations de fonctions paramétriques qui permettent de construire une architecture beaucoup plus rapidement que ce que nous avons fait jusqu'à présent. Ces fonctions se trouvent dans le paquet `torch.nn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de la transformation affine générale (\"Fully Connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  Parameter containing:\n",
      "tensor([[-0.0043,  0.3097, -0.4752],\n",
      "        [-0.4249, -0.2224,  0.1548]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([-0.0114,  0.4578], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "linear = nn.Linear(3, 2)\n",
    "print ('w: ', linear.weight)\n",
    "print ('b: ', linear.bias)\n",
    "\n",
    "x = torch.randn(10, 3)\n",
    "pred = linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que cette fonctionnalité \"cache\" beaucoup de détails d'implémentation. Par exemple concernant la fonction `nn.linear`, ses paramètres sont définis implicitement ainsi que la méthode d'initialisation de leurs valeurs.\n",
    "\n",
    "En modifiant la classe `class MLP` (de l'implémentation utilisant l'autograd) en faisant usage du paquet `torch.nn` on obtient l'implémentation suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, H, C, D):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.C = C #output size i.e number of classes for a classification task\n",
    "        self.D = D #input size (784 for MNIST)\n",
    "        self.H = H #hidden layer size\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.D, self.H) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(self.H, self.C)  \n",
    "        \n",
    "        #init parameters\n",
    "        with t.no_grad():\n",
    "            self.fc1.weight.uniform_(-math.sqrt(6./self.D), math.sqrt(6./self.D))\n",
    "            self.fc1.bias.uniform_(-1./math.sqrt(self.D), 1./math.sqrt(self.D))\n",
    "            self.fc3.weight.uniform_(-math.sqrt(6./self.H),math.sqrt(6./self.H))\n",
    "            self.fc3.bias.uniform_(-1./math.sqrt(self.H),1./math.sqrt(self.H))\n",
    "        \n",
    "    def forward(self,X):\n",
    "    \n",
    "        X1 = self.fc1(X) #NxH\n",
    "        X2 = self.relu(X1) #NxH\n",
    "        S = self.fc3(X2) #NxC\n",
    "    \n",
    "        return X,X1,X2,S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parmi les fonctions disponibles, `torch.nn` contient également les fonctions de coûts les plus communément utilisées. Ainsi la fonction `multinoulliCrossEntropyLoss` peut être remplacée par son équivalent PyTorch `nn.CrossEntropyLoss`.\n",
    "\n",
    "#### Remarque : la fonction de validation permettant d'évaluer les performances du réseau à la fin de chaque epoch devrait utiliser `with torch.no_grad():` car nous n'avons pas besoin de calculer de gradient pendant la validation.\n",
    "\n",
    "Le code obtenu devrait désormais être grandement simplifié par rapport au code initial utilisant Numpy, mais devrait fonctionner exactement comme auparavant.  \n",
    "  \n",
    "Si vous êtes bloqués, vous pouvez vous référer à cette correction : [main_MLP_two_layers_MNIST_nn_pytorch.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/IA201/correction/main_MLP_two_layers_MNIST_nn_pytorch.py) et [utils_nn.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/IA201/correction/utils_nn.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Utilisation du paquet `torch.optim`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plusieurs algorithmes d'optimisation sont également disponibles dans le paquet `torch.optim`. \n",
    "\n",
    "Lire la page de la documentation concernant ce paquet https://pytorch.org/docs/stable/optim.html?highlight=torch%20optim#module-torch.optim.\n",
    "\n",
    "Utiliser l'algorithme `torch.optim.SGD` pour simplifier le code précédent.\n",
    "\n",
    "Vous pouvez comparer votre code à cette correction : [main_MLP_two_layers_MNIST_optim_pytorch.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/IA201/correction/main_MLP_two_layers_MNIST_optim_pytorch.py) et [utils_nn.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/IA201/correction/utils_optim.py) \n",
    "\n",
    "Et le modèle sauvegardé peut être testé avec le script suivant : [main_test_model.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/IA201/correction/main_test_model.py) \n",
    "  \n",
    "Observer comme le code est beaucoup plus court par rapport au début du TP, mais un certain nombre de choses sont désormais cachées. Désormais vous savez ce qui se cache dedans !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V) TensorBoard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichages**  \n",
    "Le code de correction utilise Matplotlib pour réaliser les affichages. Nous allons désormais utiliser un outil dédié : **TensorBoard**.  \n",
    "  \n",
    "TensorBoard est un outil de visualisation dédié aux expériences d'appentissage automatique. Il permet notamment de tracer des courbes au cours de l'entraînement ou encore de superposer des courbes issues de différents entraînement.\n",
    "Un exemple d'utilisation est présenté ici : https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html\n",
    "\n",
    "L'objectif de cette partie est d'utiliser cet outil, en rajoutant quelques lignes de code à votre code d'entraînement du MLP sur MNIST (essentiellement `from torch.utils.tensorboard import SummaryWriter\n",
    "`, `writer = SummaryWriter()`, `writer.add_scalar(...)`)\n",
    " , pour afficher des informations relatives à l'entraînement en cours (courbe du coût d'apprentissage, courbe du coût de validation, courbe de la précision de validation, valeur du pas d'apprentissage au cours du temps, valeurs de certains gradients, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus : MNIST décentré\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les images de la base de données MNIST sont de taille 28x28. Dans chaque image, le chiffre se situe au centre de l'image. \n",
    "\n",
    "L'objectif de cette partie est de modifier le `Dataset` pour obtenir des images de taille 56x56 où le chiffre n'est plus centré. Ceci peut par exemple être implémenté dans la méthode `__get_item__` en générant une translation aléatoire (en x et en y) et en l'appliquant à l'image chargée.\n",
    "\n",
    "Cette nouvelle base de donnée, qu'on appellera *MNISTTranslation*, correspond à un problème d'apprentissage supervisé plus difficile que le problème initial. Pourquoi ? \n",
    "\n",
    "Lancer un entraînement avec le MLP précédemment implémenté. Que constatez-vous ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
