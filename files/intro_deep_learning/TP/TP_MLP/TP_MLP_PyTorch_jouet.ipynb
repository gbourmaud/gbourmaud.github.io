{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# TP MLP PyTorch \n",
    "Dans ce TP, vous allez implémenter un réseau de neurones de type *Perceptron Multicouche* en utilisant la bibliothèque PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "### Si vous utilisez un ordinateur de l'Enseirb:\n",
    "#### 1) Lancer une session linux (et non pas windows)\n",
    "#### 2) Aller dans \"Applications\", puis \"Autre\", puis \"conda_pytorch\" (un terminal devrait s'ouvrir)\n",
    "#### 3) Dans ce terminal, taper la commande suivante pour lancer Spyder :  \n",
    "`spyder &`  \n",
    "### Si vous utilisez votre ordinateur personnel, il faudra installer Spyder.  \n",
    "\n",
    "---\n",
    "---\n",
    "## Dans tous les cas, ne pas oublier de configurer Spyder en suivant ces [instructions](https://gbourmaud.github.io/files/configuration_spyder_annotated.pdf).\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I) Introduction à PyTorch\n",
    "La documentation de la bibliothèque PyTorch est [ici](https://pytorch.org/docs/1.12/ ). Il est également possible d'accéder à la documentation d'une fonction en tapant `help(torch.nom_de_la_fonction)` dans le terminal python de Spyder (exemple : `help(torch.matmul)` après avoir importé la biblitohèque PyTorch `import torch`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer un nouveau script python et copier/coller le code suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "### Fonctionnalité \"autograd\" de PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un `torch.tensor` est l'équivalent en PyTorch d'un `numpy.array` en Numpy : il s'agit d'un tableau multidimensionnel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemple de création d'un tableau bidimensionnel\n",
    "x = torch.tensor([[1, 2, 3],[4, 5 ,6], [7, 8 ,9], [10, 11, 12]])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La principale différence entre un `numpy.array` et un `torch.tensor` est le fait que le `torch.tensor` permet l'utilisation de la fonctionnalité *autograd* (option `requires_grad=True`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemple de création d'un tableau bidimensionnel en activant l'autograd\n",
    "x = torch.tensor([[1., 2., 3.],[4., 5. ,6.], [7., 8. ,9.], [10., 11., 12.]],requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque cette fonctionnalité est activée pour un `torch.tensor` $X$ , un graphe de calcul se crée et chaque opération faisant intervenir (directement ou indirectement) $X$ est ajoutée à ce graphe de calcul. Tout ce processus est transparent pour l'utilisateur. Ce processus de création d'un graphe de calcul correspond à l'étape de **propagation avant** vue en cours.  Lorsque la méthode `.backward()` d'une variable `torch.tensor` $y$ **scalaire** du graphe de calcul, est exécutée, l'étape de **rétropropagation** s'effectue et calcule la dérivée $\\frac{\\partial y}{\\partial X}$. Le résultat est stockée dans le champs `x.grad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemple d'utilisation de l'autograd avec des scalaires\n",
    "\n",
    "# Création des tenseurs scalaires\n",
    "x = torch.tensor(1., requires_grad=True)\n",
    "w = torch.tensor(2.)\n",
    "b = torch.tensor(3.)\n",
    "\n",
    "print(x.grad) # None\n",
    "\n",
    "# Construction du graphe de calcul (propagation avant)\n",
    "z = w*x\n",
    "y = z+b # y = 2*x + 3\n",
    "\n",
    "# Calcul du gradient (rétropropagation)\n",
    "y.backward(torch.tensor(1.))\n",
    "\n",
    "# Affichage du gradient\n",
    "print(x.grad)    # x.grad = 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dessiner (sur papier) le graphe de calcul de l'exemple précédent.** Dans ce graphe, vous remarquerez qu'il y a trois *feuilles* : le tenseur $x$, le tenseur $w$ et le tenseur $b$. Pour obtenir  $\\frac{\\partial y}{\\partial w}$ et $\\frac{\\partial y}{\\partial b}$ en plus de $\\frac{\\partial y}{\\partial x}$, il suffit d'utiliser l'option `requires_grad=True` sur $w$ et $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemple d'utilisation de l'autograd avec des scalaires\n",
    "\n",
    "# Création des tenseurs scalaires\n",
    "x = torch.tensor(4., requires_grad=True)\n",
    "w = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)\n",
    "\n",
    "print(x.grad) # None\n",
    "print(w.grad) # None\n",
    "print(b.grad) # None\n",
    "\n",
    "# Construction du graphe de calcul (propagation avant)\n",
    "z = w*x\n",
    "y = z+b\n",
    "\n",
    "# Calcul des gradients (rétropropagation)\n",
    "y.backward(torch.tensor(1.))\n",
    "\n",
    "# Affichage des gradients\n",
    "print(x.grad)    # x.grad = 2.\n",
    "print(w.grad)    # w.grad = 4. \n",
    "print(b.grad)    # b.grad = 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce mécanisme d'autograd fonctionne de la même manière lorsque les feuilles sont des tableaux multimensionnels plutôt que des scalaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemple d'utilisation de l'autograd avec des tenseurs 2D\n",
    "\n",
    "# Création des tenseurs\n",
    "X = torch.tensor([[1., 2., 3.],[4., 5. ,6.], [7., 8. ,9.], [10., 11., 12.]],requires_grad=True) #tableau 4x3 \n",
    "W = torch.tensor([[1., 2.],[4., 5.], [7., 8.]],requires_grad=True) #tableau 3x2 \n",
    "b = torch.tensor([4., 5.], requires_grad=True) #vecteur de taille 2\n",
    "\n",
    "\n",
    "# Construction du graphe de calcul (propagation avant)\n",
    "z1 = X.matmul(W)\n",
    "z2 = z1 + b\n",
    "y = z2.sum()\n",
    "\n",
    "# Calcul des gradients (rétropropagation)\n",
    "y.backward(torch.tensor(1.))\n",
    "\n",
    "# Affichage des gradients\n",
    "print(X.grad)\n",
    "print(W.grad)\n",
    "print(b.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dessiner (sur papier) le graphe de calcul de l'exemple précédent.** Quelle devrait-être les tailles des variables `X.grad`, `W.grad` et `b.grad` ? Vérifier leurs tailles dans le code (attribut `.shape` d'un tenseur)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous venons de la voir, la fonctionnalité *autograd* est une implémentation du théorème de dérivation d'une fonction composée. Pour s'en convaincre, prenons le cas de la composition de deux fonctions $y=g(Z)$ et $Z=f(X)$. Nous allons comparer deux utilisations de l'autograd :\n",
    "\n",
    "Cas 1) Calculer directement $\\frac{\\partial y}{\\partial X}$ avec l'autograd\n",
    "\n",
    "Cas 2) Calculer manuellement $\\frac{\\partial y}{\\partial Z}$ (variable `dy_dZ`) et fournir ce gradient à l'autograd (`Z.backward(dy_dZ)`) pour qu'il termine le calcule de $\\frac{\\partial y}{\\partial X}$.\n",
    "\n",
    "Les gradients obtenus avec le cas 1 et le cas 2 doivent être parfaitement identiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAS 1\n",
    "\n",
    "# Création des tenseurs\n",
    "X = torch.tensor([[1., 2., 3.],[4., 5. ,6.], [7., 8. ,9.], [10., 11., 12.]],requires_grad=True) #tableau 4x3 \n",
    "W = torch.tensor([[1., 2.],[4., 5.], [7., 8.]],requires_grad=True) #tableau 3x2 \n",
    "\n",
    "# Construction du graphe de calcul (propagation avant)\n",
    "Z = X.matmul(W)\n",
    "y = Z.sum()\n",
    "\n",
    "y.backward(torch.tensor(1.))\n",
    "\n",
    "print(X.grad)\n",
    "# CAS 2\n",
    "\n",
    "# Création des tenseurs\n",
    "X = torch.tensor([[1., 2., 3.],[4., 5. ,6.], [7., 8. ,9.], [10., 11., 12.]],requires_grad=True) #tableau 4x3 \n",
    "W = torch.tensor([[1., 2.],[4., 5.], [7., 8.]],requires_grad=True) #tableau 3x2 \n",
    "\n",
    "# Construction du graphe de calcul (propagation avant)\n",
    "Z = X.matmul(W)\n",
    "y = Z.sum()\n",
    "\n",
    "dy_dZ = torch.ones(Z.shape) #dérivée de la fonction sum\n",
    "Z.backward(dy_dZ)\n",
    "\n",
    "print(X.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II) Du MLP en Numpy au MLP en Pytorch sans *autograd*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Télécharger l'implémentation du MLP **en PyTorch** [main_MLP_two_layers_pytorch_without_autograd.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/misc/main_MLP_two_layers_pytorch_without_autograd.py) ainsi que le fichier [utils.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/misc/utils.py). Vérifier que le code fonctionne (le résultat devrait être quasi-identique à celui du TP précédent).  \n",
    "  \n",
    "Vous remarquerez que la bibliothèqe Numpy n'est plus utilisée, et à été entièrement remplacée par PyTorch.\n",
    "\n",
    "**Il n'y a pas de travail à effectuer dans cette partie.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III) Utilisation de la fonctionnalité *autograd*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de cette partie consiste à remplacer, dans le code de la partie précédente, l'implémentation manuelle de la rétropropagation par la fonctionnalité *autograd*. Ainsi :\n",
    "* la méthode `def backward(self,dc_dS, S, X2, X1, X0)` de la classe `class MLP` doit être supprimée, et l'appel à cette méthode remplacé par l'appel à la méthode `.backward()` de l'autograd comme vu précédemment (`S.backward(dc_dS)`),\n",
    "* il faut activer le calcul des gradients des paramètres `W1`, `b1`, etc. (méthode `.requires_grad_()`), supprimer les variables gradients `dc_dW1`, `dc_db1`, etc.  \n",
    "* il faut modifier `GradientDescentWithMomentum` pour qu'il utilise les champs `.grad` des paramètres (car les variables gradients `dc_dW1`, `dc_db1`, etc. n'existent plus), et mettre au début de la méthode `def step(self):` `with t.no_grad():` pour que les opérations qui suivent ne soient pas mises dans le graphe de calcul.\n",
    "\n",
    "\n",
    "Le code obtenu devrait fonctionner exactement comme dans la partie précédente.  \n",
    "Si vous êtes bloqués, vous pouvez vous référez à cette correction : [main_MLP_two_layers_pytorch_with_autograd.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/misc/main_MLP_two_layers_pytorch_with_autograd.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV) Utilisation du paquet `torch.nn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En plus de la fonctionnalité autograd, la bibliothèque PyTorch contient de nombreuses implémentations de fonctions paramétriques qui permettent de construire une architecture beaucoup plus rapidement que ce que nous avons fait jusqu'à présent. Ces fonctions se trouvent dans le paquet `torch.nn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de la transformation affine générale (\"Fully Connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "linear = nn.Linear(3, 2)\n",
    "print ('w: ', linear.weight)\n",
    "print ('b: ', linear.bias)\n",
    "\n",
    "x = torch.randn(10, 3)\n",
    "pred = linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que cette fonctionnalité \"cache\" beaucoup de détails d'implémentation. Par exemple concernant la fonction `nn.linear`, ses paramètres sont définis implicitement ainsi que la méthode d'initialisation de leurs valeurs.\n",
    "\n",
    "En modifiant la classe `class MLP` (de l'implémentation utilisant l'autograd) en faisant usage du paquet `torch.nn` on obtient l'implémentation suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, H):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.C = 3\n",
    "        self.D = 2\n",
    "        self.H = H\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.D, self.H) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(self.H, self.C)  \n",
    "        \n",
    "        #init parameters\n",
    "        with t.no_grad():\n",
    "            self.fc1.weight.uniform_(-math.sqrt(6./self.D), math.sqrt(6./self.D))\n",
    "            self.fc1.bias.uniform_(-1./math.sqrt(self.D), 1./math.sqrt(self.D))\n",
    "            self.fc3.weight.uniform_(-math.sqrt(6./self.H),math.sqrt(6./self.H))\n",
    "            self.fc3.bias.uniform_(-1./math.sqrt(self.H),1./math.sqrt(self.H))\n",
    "        \n",
    "    def forward(self,X):\n",
    "    \n",
    "        X1 = self.fc1(X) #NxH\n",
    "        X2 = self.relu(X1) #NxH\n",
    "        S = self.fc3(X2) #NxC\n",
    "    \n",
    "        return X,X1,X2,S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parmi les fonctions disponibles, `torch.nn` contient également les fonctions de coûts les plus communément utilisées. Ainsi la fonction `multinoulliCrossEntropyLoss` peut être remplacée par son équivalent PyTorch `nn.CrossEntropyLoss`.\n",
    "\n",
    "Le code obtenu devrait désormais être grandement simplifié par rapport au code initial utilisant Numpy, mais devrait fonctionner exactement comme auparavant.  \n",
    "Si vous êtes bloqués, vous pouvez vous référez à cette correction : [main_MLP_two_layers_pytorch_with_nn.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/misc/main_MLP_two_layers_pytorch_with_nn.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V) Utilisation du paquet `torch.optim`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plusieurs algorithmes d'optimisation sont également disponibles dans le paquet `torch.optim`. \n",
    "\n",
    "Lire la page de la documentation concernant ce paquet https://pytorch.org/docs/stable/optim.html?highlight=torch%20optim#module-torch.optim.\n",
    "\n",
    "Utiliser l'algorithme `torch.optim.SGD` pour simplifier le code précédent.\n",
    "\n",
    "Si vous êtes bloqués, vous pouvez vous référez à cette correction : [main_MLP_two_layers_pytorch_with_optim.py](https://gbourmaud.github.io/files/intro_deep_learning/TP/TP_MLP/misc/main_MLP_two_layers_pytorch_with_optim.py).  \n",
    "  \n",
    "Observer comme le code est beaucoup plus court par rapport au début du TP, mais un certain nombre de choses sont désormais cachées. Désormais vous savez ce qui se cache dedans !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
